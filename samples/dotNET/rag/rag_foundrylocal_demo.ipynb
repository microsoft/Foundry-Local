{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6729525b",
   "metadata": {},
   "source": [
    "# Foundry Local RAG Implementation Guide\n",
    "\n",
    "This notebook demonstrates how to build a Retrieval-Augmented Generation (RAG) system using Foundry Local with Semantic Kernel, ONNX embeddings, and Qdrant vector database.\n",
    "\n",
    "## Package Installation\n",
    "\n",
    "First, we install the required NuGet packages for Semantic Kernel and related components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f573fa",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel, 1.60.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 1.60.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f0b48a",
   "metadata": {},
   "source": [
    "### Install Microsoft Semantic Kernel Core Package\n",
    "\n",
    "Installing the main Semantic Kernel package which provides the core functionality for building AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2beb6393",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel.Connectors.Onnx, 1.60.0-alpha</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.Onnx, 1.60.0-alpha\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c548be",
   "metadata": {},
   "source": [
    "### Install Semantic Kernel ONNX Connector\n",
    "\n",
    "Installing the ONNX connector package which enables using ONNX models for embeddings generation in Semantic Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc62e7be",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel.Connectors.Onnx, 1.60.0-alpha</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.Onnx, 1.60.0-alpha\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bff756",
   "metadata": {},
   "source": [
    "### Duplicate ONNX Connector Installation\n",
    "\n",
    "Note: This is a duplicate installation of the ONNX connector package (same as the previous cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel.Connectors.Qdrant, 1.60.0-preview</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.Qdrant, 1.60.0-preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d8590",
   "metadata": {},
   "source": [
    "### Install Semantic Kernel Qdrant Connector\n",
    "\n",
    "Installing the Qdrant connector package to enable vector database operations with Semantic Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>qdrant.client, 1.14.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Qdrant.Client, 1.14.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a887bc53",
   "metadata": {},
   "source": [
    "### Install Qdrant Client\n",
    "\n",
    "Installing the official Qdrant client library for direct communication with the Qdrant vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab040e4",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ab7920",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "### Import Semantic Kernel\n",
    "\n",
    "Importing the core Semantic Kernel namespace to access the main functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c08e21",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var builder = Kernel.CreateBuilder();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93e70fc",
   "metadata": {},
   "source": [
    "### Create Kernel Builder\n",
    "\n",
    "Creating a kernel builder instance which will be used to configure and build the Semantic Kernel with various services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0eb9fc",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var embeddModelPath = \"Your Jinaai jina-embeddings-v2-base-en onnx model path\";\n",
    "var embedVocab = \"Your Jinaai ina-embeddings-v2-base-en vocab file path\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4ae93",
   "metadata": {},
   "source": [
    "### Define Embedding Model Paths\n",
    "\n",
    "Setting up file paths for the JINA embedding model files - the ONNX model file and vocabulary file needed for text embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f48625de",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "builder.AddBertOnnxEmbeddingGenerator(embeddModelPath, embedVocab);\n",
    "builder.AddOpenAIChatCompletion(\"qwen2.5-0.5b-instruct-generic-gpu\", new Uri(\"http://localhost:5273/v1\"), apiKey: \"\", serviceId: \"qwen2.5-0.5b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf5a34",
   "metadata": {},
   "source": [
    "### Configure AI Services\n",
    "\n",
    "Adding the BERT ONNX embedding generator and OpenAI-compatible chat completion service to the kernel builder. The chat service connects to a local Foundry Local instance running the Qwen2.5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5efe8c9",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var kernel = builder.Build();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c210d5",
   "metadata": {},
   "source": [
    "### Build the Kernel\n",
    "\n",
    "Building the final kernel instance with all configured services (embedding generator and chat completion service)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.Embeddings;\n",
    "using Microsoft.SemanticKernel.ChatCompletion;\n",
    "using Microsoft.Extensions.AI;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb43e167",
   "metadata": {},
   "source": [
    "### Import Additional Required Namespaces\n",
    "\n",
    "Importing namespaces for embeddings, chat completion, and Microsoft Extensions AI functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System.Net.Http;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f690259",
   "metadata": {},
   "source": [
    "### Import HTTP Client\n",
    "\n",
    "Importing System.Net.Http for HTTP communication capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "using Microsoft.SemanticKernel.Memory;\n",
    "using Microsoft.SemanticKernel.Connectors.Qdrant;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b8ade",
   "metadata": {},
   "source": [
    "### Import Memory and Vector Database Connectors\n",
    "\n",
    "Importing Semantic Kernel memory functionality and Qdrant connector for vector database operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Qdrant.Client;\n",
    "using Qdrant.Client.Grpc;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326b2cda",
   "metadata": {},
   "source": [
    "### Import Qdrant Client Libraries\n",
    "\n",
    "Importing the Qdrant client and gRPC libraries for direct communication with the Qdrant vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "public class VectorStoreService\n",
    "{\n",
    "    private readonly QdrantClient _client;\n",
    "    private readonly string _collectionName;\n",
    "\n",
    "    public VectorStoreService(string endpoint, string apiKey, string collectionName)\n",
    "    {\n",
    "        _client = new QdrantClient(new Uri(endpoint));\n",
    "        _collectionName = collectionName;\n",
    "    }\n",
    "\n",
    "    public async Task InitializeAsync(int vectorSize = 768)\n",
    "    {\n",
    "        try\n",
    "        {\n",
    "            await _client.GetCollectionInfoAsync(_collectionName);\n",
    "        }\n",
    "        catch\n",
    "        {\n",
    "            await _client.CreateCollectionAsync(_collectionName, new VectorParams\n",
    "            {\n",
    "                Size = (ulong)vectorSize,\n",
    "                Distance = Distance.Cosine\n",
    "            });\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public async Task UpsertAsync(string id, ReadOnlyMemory<float> embedding, Dictionary<string, object> metadata)\n",
    "    {\n",
    "        var point = new PointStruct\n",
    "        {\n",
    "            Id = new PointId { Uuid = id },\n",
    "            Vectors = embedding.ToArray(),\n",
    "            Payload = { }\n",
    "        };\n",
    "\n",
    "        foreach (var kvp in metadata)\n",
    "        {\n",
    "            point.Payload[kvp.Key] = kvp.Value switch\n",
    "            {\n",
    "                string s => s,\n",
    "                int i => i,\n",
    "                bool b => b,\n",
    "                _ => kvp.Value.ToString() ?? string.Empty\n",
    "            };\n",
    "        }\n",
    "\n",
    "        await _client.UpsertAsync(_collectionName, new[] { point });\n",
    "    }\n",
    "\n",
    "    public async Task<List<ScoredPoint>> SearchAsync(ReadOnlyMemory<float> queryEmbedding, int limit = 3)\n",
    "    {\n",
    "        var searchResult = await _client.SearchAsync(_collectionName, queryEmbedding.ToArray(), limit: (ulong)limit);\n",
    "        return searchResult.ToList();\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f7d8f",
   "metadata": {},
   "source": [
    "## Service Classes\n",
    "\n",
    "### Vector Store Service Class\n",
    "\n",
    "This class provides a wrapper around the Qdrant client to handle vector database operations including:\n",
    "- Collection initialization with proper vector configuration\n",
    "- Upserting vectors with metadata\n",
    "- Searching for similar vectors using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "public class RagQueryService\n",
    "{\n",
    "    private readonly IEmbeddingGenerator<string, Embedding<float>> _embeddingService;\n",
    "    private readonly IChatCompletionService _chatService;\n",
    "    private readonly VectorStoreService _vectorStoreService;\n",
    "\n",
    "    public RagQueryService(\n",
    "        IEmbeddingGenerator<string, Embedding<float>> embeddingService,\n",
    "        IChatCompletionService chatService,\n",
    "        VectorStoreService vectorStoreService)\n",
    "    {\n",
    "        _embeddingService = embeddingService;\n",
    "        _chatService = chatService;\n",
    "        _vectorStoreService = vectorStoreService;\n",
    "    }\n",
    "\n",
    "    public async Task<string> QueryAsync(string question)\n",
    "    {\n",
    "        // return question; // For now, just return the question as a placeholder\n",
    "           var queryEmbeddingResult = await _embeddingService.GenerateAsync(question);\n",
    "//         Console.WriteLine(question);\n",
    "            var queryEmbedding = queryEmbeddingResult.Vector;\n",
    "            var searchResults = await _vectorStoreService.SearchAsync(queryEmbedding, limit: 5);\n",
    "\n",
    "            string str_context = \"\";\n",
    "            foreach (var result in searchResults)\n",
    "            {\n",
    "                if (result.Payload.TryGetValue(\"text\", out var text))\n",
    "                {\n",
    "                    str_context += text.ToString();\n",
    "                }\n",
    "            }\n",
    "            var prompt = $@\"According to the question {question},, optimize and simplify the content. {str_context}\";\n",
    "\n",
    "\n",
    "            var chatHistory = new ChatHistory();\n",
    "            chatHistory.AddSystemMessage(\"You are a helpful assistant that answers questions based on the provided context.\");\n",
    "            chatHistory.AddUserMessage(prompt);\n",
    "\n",
    "            var fullMessage = string.Empty;\n",
    "\n",
    "            await foreach (var chatUpdate in _chatService.GetStreamingChatMessageContentsAsync(chatHistory, cancellationToken: default))\n",
    "            {                     \n",
    "                if (chatUpdate.Content is { Length: > 0 })\n",
    "                {\n",
    "                    fullMessage += chatUpdate.Content;\n",
    "                }\n",
    "            }\n",
    "            return fullMessage ?? \"I couldn't generate a response.\";\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc8eee3",
   "metadata": {},
   "source": [
    "### RAG Query Service Class\n",
    "\n",
    "This service implements the core RAG (Retrieval-Augmented Generation) functionality:\n",
    "1. Converts user questions into embeddings\n",
    "2. Searches for relevant context from the vector database\n",
    "3. Combines the retrieved context with the user question\n",
    "4. Generates responses using the chat completion service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using System.IO;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2e2e9",
   "metadata": {},
   "source": [
    "### Import File I/O\n",
    "\n",
    "Importing System.IO for file reading operations needed for document ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "public class DocumentIngestionService\n",
    "{\n",
    "    private readonly IEmbeddingGenerator<string, Embedding<float>> _embeddingService;\n",
    "    private readonly VectorStoreService _vectorStoreService;\n",
    "\n",
    "    public DocumentIngestionService(IEmbeddingGenerator<string, Embedding<float>> embeddingService, VectorStoreService vectorStoreService)\n",
    "    {\n",
    "        _embeddingService = embeddingService;\n",
    "        _vectorStoreService = vectorStoreService;\n",
    "    }\n",
    "\n",
    "    public async Task IngestDocumentAsync(string documentPath, string documentId)\n",
    "    {\n",
    "        var content = await File.ReadAllTextAsync(documentPath);\n",
    "        var chunks = ChunkText(content, 300, 60);\n",
    "\n",
    "        for (int i = 0; i < chunks.Count; i++)\n",
    "        {\n",
    "            var chunk = chunks[i];\n",
    "            var embeddingResult = await _embeddingService.GenerateAsync(chunk);\n",
    "            var embedding = embeddingResult.Vector;\n",
    "            \n",
    "            await _vectorStoreService.UpsertAsync(\n",
    "                id: Guid.NewGuid().ToString(),\n",
    "                embedding: embedding,\n",
    "                metadata: new Dictionary<string, object>\n",
    "                {\n",
    "                    [\"document_id\"] = documentId,\n",
    "                    [\"chunk_index\"] = i,\n",
    "                    [\"text\"] = chunk,\n",
    "                    [\"document_path\"] = documentPath\n",
    "                }\n",
    "            );\n",
    "        }\n",
    "    }\n",
    "\n",
    "    private List<string> ChunkText(string text, int chunkSize, int overlap)\n",
    "    {\n",
    "        var chunks = new List<string>();\n",
    "        var words = text.Split(' ', StringSplitOptions.RemoveEmptyEntries);\n",
    "        \n",
    "        for (int i = 0; i < words.Length; i += chunkSize - overlap)\n",
    "        {\n",
    "            var chunkWords = words.Skip(i).Take(chunkSize).ToArray();\n",
    "            var chunk = string.Join(\" \", chunkWords);\n",
    "            chunks.Add(chunk);\n",
    "            \n",
    "            if (i + chunkSize >= words.Length)\n",
    "                break;\n",
    "        }\n",
    "        \n",
    "        return chunks;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5845c7",
   "metadata": {},
   "source": [
    "### Document Ingestion Service Class\n",
    "\n",
    "This service handles the process of ingesting documents into the vector database:\n",
    "1. Reads document content from files\n",
    "2. Splits text into chunks with configurable size and overlap\n",
    "3. Generates embeddings for each chunk\n",
    "4. Stores chunks with embeddings and metadata in the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "using Microsoft.SemanticKernel.ChatCompletion;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1828967e",
   "metadata": {},
   "source": [
    "### Additional Chat Completion Import\n",
    "\n",
    "Additional import for chat completion functionality (note: this might be a duplicate import)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var chatService = kernel.GetRequiredService<IChatCompletionService>(serviceKey: \"qwen2.5-0.5b\");\n",
    "var embeddingService = kernel.GetRequiredService<IEmbeddingGenerator<string, Embedding<float>>>();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfafaac",
   "metadata": {},
   "source": [
    "## Initialize Services\n",
    "\n",
    "### Get Services from Kernel\n",
    "\n",
    "Retrieving the chat completion service and embedding generator from the configured kernel using their service keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var vectorStoreService = new VectorStoreService(\n",
    "    \"http://localhost:6334\",\n",
    "    \"\",\n",
    "    \"demodocs\");\n",
    "\n",
    "await vectorStoreService.InitializeAsync();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29fd60",
   "metadata": {},
   "source": [
    "### Create and Initialize Vector Store Service\n",
    "\n",
    "Creating a VectorStoreService instance pointing to a local Qdrant instance and initializing the collection for storing document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var documentIngestionService = new DocumentIngestionService(embeddingService, vectorStoreService);\n",
    "var ragQueryService = new RagQueryService(embeddingService, chatService, vectorStoreService);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a4751",
   "metadata": {},
   "source": [
    "### Create Service Instances\n",
    "\n",
    "Creating instances of the DocumentIngestionService and RagQueryService with the necessary dependencies (embedding service, chat service, and vector store service)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var filePath = \"./foundry-local-architecture.md\";\n",
    "var fileID = \"3\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b13842",
   "metadata": {},
   "source": [
    "## Document Ingestion Demo\n",
    "\n",
    "### Define Document Information\n",
    "\n",
    "Setting up the file path and document ID for the Foundry Local architecture document that will be ingested into the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "await documentIngestionService.IngestDocumentAsync(filePath, fileID);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c08b5e",
   "metadata": {},
   "source": [
    "### Ingest Document into Vector Database\n",
    "\n",
    "Processing the Foundry Local architecture document by reading its content, chunking it, generating embeddings for each chunk, and storing them in the vector database with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var question = \"What's Foundry Local?\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a25d4",
   "metadata": {},
   "source": [
    "## RAG Query Demo\n",
    "\n",
    "### Define Query Question\n",
    "\n",
    "Setting up a test question to demonstrate the RAG functionality - asking about what Foundry Local is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var answer = await ragQueryService.QueryAsync(question);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1803c",
   "metadata": {},
   "source": [
    "### Execute RAG Query\n",
    "\n",
    "Running the RAG query which will:\n",
    "1. Convert the question to embeddings\n",
    "2. Search for relevant context in the vector database\n",
    "3. Combine retrieved context with the question\n",
    "4. Generate a response using the chat completion service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Here's a simplified version of the text:\n",
       "\n",
       "---\n",
       "\n",
       "**Title:** Introduction to Foundry Local\n",
       "\n",
       "**Overview:** Foundry Local is a design focused on optimizing AI model inference on local devices. This guide explores the core components of Foundry Local and their interactions.\n",
       "\n",
       "**Key Components**:\n",
       "- Built-in System Platform (OSX)\n",
       "- REST Server Framework (API)\n",
       "- Local Execution Provider\n",
       "- Model Manager\n",
       "- Cloud Connectivity Framework\n",
       "\n",
       "### Foundry Local Services Overview\n",
       "\n",
       "- Endpoint: http://localhost:PORT/v1  \n",
       "- Use Case: Run Models Locally, Access the Local Executor.\n",
       "- ONNX Runtime: Utilizes optimized ONNX models to support local inference.\n",
       "\n",
       "### ONNX Runtime\n",
       "\n",
       "- Supported by Multiple Providers: NVIDIA, AMD, Intel (supported by OSLC).\n",
       "- Provides Unified Interface for All Providers.\n",
       "\n",
       "### Model Management\n",
       "- Model Cache (local storage): Automatically generated when models are downloaded from the OSX platform.\n",
       "- TTL for Memory Storage: Determines how long models"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a335e",
   "metadata": {},
   "source": [
    "### Display RAG Response\n",
    "\n",
    "Displaying the final answer generated by the RAG system, which should contain information about Foundry Local based on the ingested document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
